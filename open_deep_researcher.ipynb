{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahwei682/MCP/blob/main/open_deep_researcher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nest_asyncio\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7cTpP9rDZW-",
        "outputId": "5a443ad2-7a8d-4fef-f315-12108c28f1a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJTo96a7DGUz"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from openai import OpenAI\n",
        "import aiohttp\n",
        "\n",
        "# =======================\n",
        "# Configuration Constants\n",
        "# =======================\n",
        "OPENROUTER_API_KEY = \"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\" # Replace with your OpenRouter API key\n",
        "SERPAPI_API_KEY = \"7f39cccc407fb2e59ce52917d178354931cd5884062b2add658a9f1bf5943508\" # Replace with your SERPAPI API key\n",
        "JINA_API_KEY = \"jina_c948193913304f68b5c6b68cf75e1987t-wKv5qheig7zcBRcrBDPmFDrER7\" # Replace with your JINA API key\n",
        "\n",
        "# Endpoints\n",
        "OPENROUTER_BASE_URL = \"https://openrouter.ai/api/v1\"\n",
        "SERPAPI_URL = \"https://serpapi.com/search\"\n",
        "JINA_BASE_URL = \"https://r.jina.ai/\"\n",
        "\n",
        "# Default LLM model (can be changed if desired)\n",
        "DEFAULT_MODEL = \"qwen/qwen3-32b:free\"\n",
        "\n",
        "# Initialize OpenAI client\n",
        "client = OpenAI(\n",
        "    base_url=OPENROUTER_BASE_URL,\n",
        "    api_key=OPENROUTER_API_KEY,\n",
        "    default_headers={\n",
        "        \"HTTP-Referer\": \"https://github.com/mshumer/OpenDeepResearcher\",\n",
        "        \"X-Title\": \"OpenDeepResearcher\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# ============================\n",
        "# API Validation Functions\n",
        "# ============================\n",
        "\n",
        "def validate_openrouter_api_key():\n",
        "    \"\"\"\n",
        "    验证OpenRouter API密钥的格式和有效性\n",
        "    \"\"\"\n",
        "    if not OPENROUTER_API_KEY:\n",
        "        print(\"错误: OpenRouter API密钥未设置\")\n",
        "        return False\n",
        "\n",
        "    if not OPENROUTER_API_KEY.startswith(\"sk-or-v1-\"):\n",
        "        print(\"错误: OpenRouter API密钥格式不正确\")\n",
        "        print(\"API密钥应该以 'sk-or-v1-' 开头\")\n",
        "        print(\"请访问 https://openrouter.ai/keys 获取正确的API密钥\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# ============================\n",
        "# Asynchronous Helper Functions\n",
        "# ============================\n",
        "\n",
        "async def call_openrouter_async(session, messages, model=DEFAULT_MODEL):\n",
        "    \"\"\"\n",
        "    异步调用OpenRouter API\n",
        "\n",
        "    参数:\n",
        "        session: aiohttp会话对象\n",
        "        messages: 对话消息列表\n",
        "        model: 使用的模型名称\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(f\"\\n正在发送请求到OpenRouter API...\")\n",
        "        print(f\"使用模型: {model}\")\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=messages,\n",
        "            extra_body={}\n",
        "        )\n",
        "\n",
        "        return completion.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n请求发生错误: {str(e)}\")\n",
        "        print(\"请检查网络连接是否正常\")\n",
        "        return None\n",
        "\n",
        "\n",
        "async def generate_search_queries_async(session, user_query):\n",
        "    \"\"\"\n",
        "    Ask the LLM to produce up to four precise search queries (in Python list format)\n",
        "    based on the user's query.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are an expert research assistant. Given the user's query, generate up to four distinct, \"\n",
        "        \"precise search queries that would help gather comprehensive information on the topic. \"\n",
        "        \"Return only a Python list of strings, for example: ['query1', 'query2', 'query3'].\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful and precise research assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"User Query: {user_query}\\n\\n{prompt}\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        extra_body={}\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    if response:\n",
        "        try:\n",
        "            # Expect exactly a Python list (e.g., \"['query1', 'query2']\")\n",
        "            search_queries = eval(response)\n",
        "            if isinstance(search_queries, list):\n",
        "                return search_queries\n",
        "            else:\n",
        "                print(\"LLM did not return a list. Response:\", response)\n",
        "                return []\n",
        "        except Exception as e:\n",
        "            print(\"Error parsing search queries:\", e, \"\\nResponse:\", response)\n",
        "            return []\n",
        "    return []\n",
        "\n",
        "\n",
        "async def perform_search_async(session, query):\n",
        "    \"\"\"\n",
        "    Asynchronously perform a Google search using SERPAPI for the given query.\n",
        "    Returns a list of result URLs.\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"api_key\": SERPAPI_API_KEY,\n",
        "        \"engine\": \"google\"\n",
        "    }\n",
        "    try:\n",
        "        async with session.get(SERPAPI_URL, params=params) as resp:\n",
        "            if resp.status == 200:\n",
        "                results = await resp.json()\n",
        "                if \"organic_results\" in results:\n",
        "                    links = [item.get(\"link\") for item in results[\"organic_results\"] if \"link\" in item]\n",
        "                    return links\n",
        "                else:\n",
        "                    print(\"No organic results in SERPAPI response.\")\n",
        "                    return []\n",
        "            else:\n",
        "                text = await resp.text()\n",
        "                print(f\"SERPAPI error: {resp.status} - {text}\")\n",
        "                return []\n",
        "    except Exception as e:\n",
        "        print(\"Error performing SERPAPI search:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "async def perform_image_search_async(session, image_url):\n",
        "    \"\"\"\n",
        "    Asynchronously perform a reverse image search using SERPAPI.\n",
        "    Returns a list of dictionaries containing thumbnails and titles of visually similar images.\n",
        "\n",
        "    Args:\n",
        "        session: aiohttp session object\n",
        "        image_url: URL of the image to search for\n",
        "\n",
        "    Returns:\n",
        "        List of dicts with 'thumbnail' and 'title' keys\n",
        "    \"\"\"\n",
        "    params = {\n",
        "        \"engine\": \"google_reverse_image\",\n",
        "        \"image_url\": image_url,\n",
        "        \"api_key\": SERPAPI_API_KEY,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        async with session.get(SERPAPI_URL, params=params) as resp:\n",
        "            if resp.status == 200:\n",
        "                results = await resp.json()\n",
        "                image_results = []\n",
        "\n",
        "                # Extract image results from the response\n",
        "                if \"image_results\" in results:\n",
        "                    for item in results[\"image_results\"]:\n",
        "                        result = {\n",
        "                            'thumbnail': item.get('thumbnail', ''),\n",
        "                            'title': item.get('title', ''),\n",
        "                            'source_url': item.get('source', '')\n",
        "                        }\n",
        "                        image_results.append(result)\n",
        "                    return image_results[:10]  # Return top 10 results\n",
        "                else:\n",
        "                    print(\"No image results in SERPAPI response.\")\n",
        "                    return []\n",
        "            else:\n",
        "                text = await resp.text()\n",
        "                print(f\"SERPAPI error: {resp.status} - {text}\")\n",
        "                return []\n",
        "    except Exception as e:\n",
        "        print(\"Error performing SERPAPI image search:\", e)\n",
        "        return []\n",
        "\n",
        "\n",
        "async def fetch_webpage_text_async(session, url):\n",
        "    \"\"\"\n",
        "    Asynchronously retrieve the text content of a webpage using Jina.\n",
        "    The URL is appended to the Jina endpoint.\n",
        "    \"\"\"\n",
        "    full_url = f\"{JINA_BASE_URL}{url}\"\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {JINA_API_KEY}\"\n",
        "    }\n",
        "    try:\n",
        "        async with session.get(full_url, headers=headers) as resp:\n",
        "            if resp.status == 200:\n",
        "                return await resp.text()\n",
        "            else:\n",
        "                text = await resp.text()\n",
        "                print(f\"Jina fetch error for {url}: {resp.status} - {text}\")\n",
        "                return \"\"\n",
        "    except Exception as e:\n",
        "        print(\"Error fetching webpage text with Jina:\", e)\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "async def is_page_useful_async(session, user_query, page_text):\n",
        "    \"\"\"\n",
        "    Ask the LLM if the provided webpage content is useful for answering the user's query.\n",
        "    The LLM must reply with exactly \"Yes\" or \"No\".\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are a critical research evaluator. Given the user's query and the content of a webpage, \"\n",
        "        \"determine if the webpage contains information relevant and useful for addressing the query. \"\n",
        "        \"Respond with exactly one word: 'Yes' if the page is useful, or 'No' if it is not. Do not include any extra text.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a strict and concise evaluator of research relevance.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"User Query: {user_query}\\n\\nWebpage Content (first 20000 characters):\\n{page_text[:20000]}\\n\\n{prompt}\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        extra_body={}\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    if response:\n",
        "        answer = response.strip()\n",
        "        if answer in [\"Yes\", \"No\"]:\n",
        "            return answer\n",
        "        else:\n",
        "            # Fallback: try to extract Yes/No from the response.\n",
        "            if \"Yes\" in answer:\n",
        "                return \"Yes\"\n",
        "            elif \"No\" in answer:\n",
        "                return \"No\"\n",
        "    return \"No\"\n",
        "\n",
        "\n",
        "async def extract_relevant_context_async(session, user_query, search_query, page_text):\n",
        "    \"\"\"\n",
        "    Given the original query, the search query used, and the page content,\n",
        "    have the LLM extract all information relevant for answering the query.\n",
        "    \"\"\"\n",
        "    prompt = (\n",
        "        \"You are an expert information extractor. Given the user's query, the search query that led to this page, \"\n",
        "        \"and the webpage content, extract all pieces of information that are relevant to answering the user's query. \"\n",
        "        \"Return only the relevant context as plain text without commentary.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are an expert in extracting and summarizing relevant information.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"User Query: {user_query}\\nSearch Query: {search_query}\\n\\nWebpage Content (first 20000 characters):\\n{page_text[:20000]}\\n\\n{prompt}\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        extra_body={}\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    if response:\n",
        "        return response.strip()\n",
        "    return \"\"\n",
        "\n",
        "\n",
        "async def get_new_search_queries_async(session, user_query, previous_search_queries, all_contexts):\n",
        "    \"\"\"\n",
        "    Based on the original query, the previously used search queries, and all the extracted contexts,\n",
        "    ask the LLM whether additional search queries are needed. If yes, return a Python list of up to four queries;\n",
        "    if the LLM thinks research is complete, it should return \"<done>\".\n",
        "    \"\"\"\n",
        "    context_combined = \"\\n\".join(all_contexts)\n",
        "    prompt = (\n",
        "        \"You are an analytical research assistant. Based on the original query, the search queries performed so far, \"\n",
        "        \"and the extracted contexts from webpages, determine if further research is needed. \"\n",
        "        \"If further research is needed, provide up to four new search queries as a Python list (for example, \"\n",
        "        \"['new query1', 'new query2']). If you believe no further research is needed, respond with exactly <done>.\"\n",
        "        \"\\nOutput only a Python list or the token <done> without any additional text.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a systematic research planner.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"User Query: {user_query}\\nPrevious Search Queries: {previous_search_queries}\\n\\nExtracted Relevant Contexts:\\n{context_combined}\\n\\n{prompt}\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        extra_body={}\n",
        "    )\n",
        "\n",
        "    response = completion.choices[0].message.content\n",
        "    if response:\n",
        "        cleaned = response.strip()\n",
        "        if cleaned == \"<done>\":\n",
        "            return \"<done>\"\n",
        "        try:\n",
        "            new_queries = eval(cleaned)\n",
        "            if isinstance(new_queries, list):\n",
        "                return new_queries\n",
        "            else:\n",
        "                print(\"LLM did not return a list for new search queries. Response:\", response)\n",
        "                return []\n",
        "        except Exception as e:\n",
        "            print(\"Error parsing new search queries:\", e, \"\\nResponse:\", response)\n",
        "            return []\n",
        "    return []\n",
        "\n",
        "\n",
        "async def generate_final_report_async(session, user_query, all_contexts):\n",
        "    \"\"\"\n",
        "    Generate the final comprehensive report using all gathered contexts.\n",
        "    \"\"\"\n",
        "    context_combined = \"\\n\".join(all_contexts)\n",
        "    prompt = (\n",
        "        \"You are an expert researcher and report writer. Based on the gathered contexts below and the original query, \"\n",
        "        \"write a comprehensive, well-structured, and detailed report that addresses the query thoroughly. \"\n",
        "        \"Include all relevant insights and conclusions without extraneous commentary.\"\n",
        "    )\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a skilled report writer.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"User Query: {user_query}\\n\\nGathered Relevant Contexts:\\n{context_combined}\\n\\n{prompt}\"}\n",
        "    ]\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=DEFAULT_MODEL,\n",
        "        messages=messages,\n",
        "        extra_body={}\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "\n",
        "async def process_link(session, link, user_query, search_query):\n",
        "    \"\"\"\n",
        "    Process a single link: fetch its content, judge its usefulness, and if useful, extract the relevant context.\n",
        "    \"\"\"\n",
        "    print(f\"Fetching content from: {link}\")\n",
        "    page_text = await fetch_webpage_text_async(session, link)\n",
        "    if not page_text:\n",
        "        return None\n",
        "    usefulness = await is_page_useful_async(session, user_query, page_text)\n",
        "    print(f\"Page usefulness for {link}: {usefulness}\")\n",
        "    if usefulness == \"Yes\":\n",
        "        context = await extract_relevant_context_async(session, user_query, search_query, page_text)\n",
        "        if context:\n",
        "            print(f\"Extracted context from {link} (first 200 chars): {context[:200]}\")\n",
        "            return context\n",
        "    return None\n",
        "\n",
        "\n",
        "async def process_image_search(session, image_url):\n",
        "    \"\"\"\n",
        "    Process an image search request and return relevant results.\n",
        "\n",
        "    Args:\n",
        "        session: aiohttp session object\n",
        "        image_url: URL of the image to search for\n",
        "\n",
        "    Returns:\n",
        "        List of image search results with thumbnails and titles\n",
        "    \"\"\"\n",
        "    print(f\"\\n开始图片搜索: {image_url}\")\n",
        "\n",
        "    # Perform the image search\n",
        "    results = await perform_image_search_async(session, image_url)\n",
        "\n",
        "    if not results:\n",
        "        print(\"未找到相关图片结果\")\n",
        "        return []\n",
        "\n",
        "    print(f\"找到 {len(results)} 个相关图片结果\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# =========================\n",
        "# API测试函数\n",
        "# =========================\n",
        "\n",
        "async def test_api_connection():\n",
        "    \"\"\"\n",
        "    测试OpenRouter API连接\n",
        "    \"\"\"\n",
        "    print(\"\\n=== 测试API连接 ===\")\n",
        "\n",
        "    try:\n",
        "        print(\"发送测试请求...\")\n",
        "\n",
        "        completion = client.chat.completions.create(\n",
        "            model=DEFAULT_MODEL,\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": \"Hello, this is a test message.\"\n",
        "                }\n",
        "            ],\n",
        "            extra_body={}\n",
        "        )\n",
        "\n",
        "        print(\"\\n✓ API连接测试成功！\")\n",
        "        print(\"测试响应:\", completion.choices[0].message.content[:100])\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n✗ API连接测试失败: {str(e)}\")\n",
        "        print(\"请检查网络连接并重试\")\n",
        "        return False\n",
        "\n",
        "# =========================\n",
        "# Main Asynchronous Routine\n",
        "# =========================\n",
        "\n",
        "async def async_main():\n",
        "    \"\"\"\n",
        "    Main asynchronous function that coordinates the research process.\n",
        "    \"\"\"\n",
        "    if not validate_openrouter_api_key():\n",
        "        return\n",
        "\n",
        "    print(\"\\n欢迎使用 OpenDeepResearcher!\")\n",
        "    print(\"这是一个强大的研究助手，可以帮助你进行深入的网络搜索和图片搜索。\")\n",
        "\n",
        "    while True:\n",
        "        print(\"\\n请选择搜索类型:\")\n",
        "        print(\"1. 文本搜索\")\n",
        "        print(\"2. 图片搜索\")\n",
        "        print(\"3. 退出\")\n",
        "\n",
        "        choice = input(\"\\n请输入选项 (1/2/3): \").strip()\n",
        "\n",
        "        if choice == \"3\":\n",
        "            print(\"\\n感谢使用 OpenDeepResearcher!\")\n",
        "            break\n",
        "\n",
        "        if choice == \"1\":\n",
        "            user_query = input(\"\\n请输入你的研究问题: \").strip()\n",
        "            if not user_query:\n",
        "                print(\"查询不能为空\")\n",
        "                continue\n",
        "\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                # Generate initial search queries\n",
        "                search_queries = await generate_search_queries_async(session, user_query)\n",
        "                if not search_queries:\n",
        "                    print(\"无法生成搜索查询\")\n",
        "                    continue\n",
        "\n",
        "                all_contexts = []\n",
        "                used_queries = []\n",
        "\n",
        "                while search_queries != \"<done>\" and isinstance(search_queries, list):\n",
        "                    for query in search_queries:\n",
        "                        if query in used_queries:\n",
        "                            continue\n",
        "\n",
        "                        print(f\"\\n执行搜索查询: {query}\")\n",
        "                        links = await perform_search_async(session, query)\n",
        "\n",
        "                        for link in links:\n",
        "                            context = await process_link(session, link, user_query, query)\n",
        "                            if context:\n",
        "                                all_contexts.append(context)\n",
        "\n",
        "                        used_queries.append(query)\n",
        "\n",
        "                    if all_contexts:\n",
        "                        search_queries = await get_new_search_queries_async(\n",
        "                            session, user_query, used_queries, all_contexts\n",
        "                        )\n",
        "                    else:\n",
        "                        search_queries = []\n",
        "\n",
        "                if all_contexts:\n",
        "                    final_report = await generate_final_report_async(session, user_query, all_contexts)\n",
        "                    print(\"\\n研究报告:\")\n",
        "                    print(final_report)\n",
        "                else:\n",
        "                    print(\"\\n未找到相关信息\")\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            image_url = input(\"\\n请输入图片URL: \").strip()\n",
        "            if not image_url:\n",
        "                print(\"图片URL不能为空\")\n",
        "                continue\n",
        "\n",
        "            async with aiohttp.ClientSession() as session:\n",
        "                results = await process_image_search(session, image_url)\n",
        "\n",
        "                if results:\n",
        "                    print(\"\\n相似图片结果:\")\n",
        "                    for i, result in enumerate(results, 1):\n",
        "                        print(f\"\\n{i}. 标题: {result['title']}\")\n",
        "                        print(f\"   缩略图: {result['thumbnail']}\")\n",
        "                        print(f\"   来源: {result['source_url']}\")\n",
        "                else:\n",
        "                    print(\"\\n未找到相关图片\")\n",
        "        else:\n",
        "            print(\"\\n无效的选项，请重试\")\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Entry point of the program.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        asyncio.run(async_main())\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\n程序已终止\")\n",
        "    except Exception as e:\n",
        "        print(f\"\\n发生错误: {str(e)}\")\n",
        "        print(\"请检查网络连接和API密钥是否正确\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "46Q5XpapDJZT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}